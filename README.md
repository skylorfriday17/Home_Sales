# Home_Sales

## About
In this challenge I used Spark to extract data from an AWS S3 Bucket and analyze it. Performed SQL queries through Spark to extract ingsights about homes built and sold between 2010 and 2017. In this repo you can find the [Home_Sales.ipynb](Jupyter_Notebooks/Home_Sales.ipynb) file under the Jupter_Notebooks directory which contains the analysis as well as the caching and partitioning of the data. In the same directory you will find a folder containing the parquet files partitioned on the year the homes were built. Lastly this directory also holds an empty notebook file for Google Colab intended use.

## Resources
In this challenge the code that I referenced was all provided within the activities files for module 22. Some SQL code was referenced from ChatGPT for filtering and assessing the dataset.